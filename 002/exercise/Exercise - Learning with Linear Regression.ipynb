{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (THIS CELL IS FOR DEVELOPMENT ONLY)\n",
    "## (THIS CELL SHOULD BE DELETED IN PRODUCTION)\n",
    "\n",
    "### Completion Progress (Approximate): 1%\n",
    "### To-Do:\n",
    "- Finish Building Skeleton of Tasks.\n",
    "- Acquire Dataset that:\n",
    "    - Dataset found: https://www.kaggle.com/c/house-prices-advanced-regression-techniques\n",
    "- Add more To-Do items (meta To-Do)\n",
    "\n",
    "### Excercise Tasks:\n",
    "- 1 - explain what the task is... input/output (features vs predicted variable)\n",
    "- 2 - \"How will we solve this?\"... present the first ML idea, Linear Regression line formula (y = w*x+b) or (y = b+w_1*x_1+w_2*x_2+...w_n*x_n)\n",
    "- 3 - \"How to evaluate a good 'w' value?\"... present the cost function\n",
    "- 4 - \"How are we going to pick a good w value\" present gradient descent on the cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hi - Welcome to the Linear Regression excercise\n",
    "\n",
    "## Run cells below which import all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn, sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cell below retreives the data and splits it into train_x, train_y, valid_x, valid_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 876, valid size: 292, test size: 292\n"
     ]
    }
   ],
   "source": [
    "# pick how big the validation/test portion of the data is, currently set to 20% validation, 20% test, and 60% train\n",
    "valid_size = 0.2\n",
    "test_size = 0.2\n",
    "\n",
    "# load the data from the .csv file\n",
    "data = pd.read_csv('../data/Housing_Prices.csv')\n",
    "# Drop the 'Id' column since it is a useless feature\n",
    "data = data.drop(columns='Id')\n",
    "\n",
    "def train_valid_test_split(data, valid_size, test_size):\n",
    "    # split into train and test\n",
    "    train, test = sklearn.model_selection.train_test_split(data, test_size=test_size)\n",
    "    # further split train into train and validation. (valid_size needs to be recalculated to properly split train)\n",
    "    valid_size = valid_size/(1-test_size)\n",
    "    train, valid = sklearn.model_selection.train_test_split(train, test_size=valid_size)\n",
    "    return train, valid, test\n",
    "\n",
    "train, valid, test = train_valid_test_split(data, valid_size, test_size)\n",
    "train_x, train_y = train.iloc[:, :-1], train.iloc[:, -1:]\n",
    "valid_x, valid_y = valid.iloc[:, :-1], valid.iloc[:, -1:]\n",
    "test_x, test_y = test.iloc[:, :-1], test.iloc[:, -1:]\n",
    "\n",
    "print(f'train size: {len(train_x)}, valid size: {len(valid_x)}, test size: {len(test_x)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cell below scales the numeric features using a min_max_scaler (scales them between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = train_x.select_dtypes(include='number').columns\n",
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "# train on concatenation of train and validation\n",
    "scaler.fit(pd.concat((train_x[numeric_columns], valid_x[numeric_columns])))\n",
    "# apply on all data\n",
    "train_x[numeric_columns] = scaler.transform(train_x[numeric_columns])\n",
    "valid_x[numeric_columns] = scaler.transform(valid_x[numeric_columns])\n",
    "test_x[numeric_columns] = scaler.transform(test_x[numeric_columns])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cell below one-hot encodes the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies_column_keys(dataFrames):\n",
    "    '''returns a column list of get dummies for concatenated dataframes'''\n",
    "    return pd.get_dummies(pd.concat(dataFrames)).columns.tolist()\n",
    "\n",
    "def get_dummies_using_keys(dataFrame, column_keys):\n",
    "    '''returns get dummies result with columns matching column_keys'''\n",
    "    result = pd.get_dummies(dataFrame)\n",
    "    result = result.reindex(columns=column_keys).fillna(0.00)\n",
    "    return result\n",
    "\n",
    "# get the keys for the concatenation of all datasets \n",
    "column_keys = get_dummies_column_keys((train_x, valid_x, test_x))\n",
    "train_x = get_dummies_using_keys(train_x, column_keys)\n",
    "valid_x = get_dummies_using_keys(valid_x, column_keys)\n",
    "test_x = get_dummies_using_keys(test_x, column_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This last cell gets the numpy arrays that we will work on from the panda dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the dataframes in df_* variables\n",
    "df_train_x, df_train_y = train_x, train_y\n",
    "df_valid_x, df_valid_y = valid_x, valid_y\n",
    "df_test_x, df_test_y = test_x, test_y\n",
    "\n",
    "# store the numpy arrays in the regular variables\n",
    "train_x, train_y = train_x.values, train_y.values\n",
    "valid_x, valid_y = valid_x.values, valid_y.values\n",
    "test_x, test_y = test_x.values, test_y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceed with any data analysis in the next cell\n",
    "\n",
    "## (Optional but heavily encouraged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example equation:\n",
    "Loss\n",
    "$$LOSS(\\theta)=\\frac{1}{2n} \\sum_{i=1}^{n} (\\hat{y}_i-y_i)^2$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
